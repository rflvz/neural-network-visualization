# ¬øC√≥mo se Actualizan los Pesos y Sesgos?

## üéØ El Problema: La Red "Aprende" Ajustando sus Par√°metros

Cuando entrenas una red neuronal, los **pesos (W)** y **sesgos (b)** empiezan con valores aleatorios o peque√±os. La red hace predicciones, compara con la respuesta correcta, y **ajusta autom√°ticamente** estos valores para mejorar.

---

## üè† Analog√≠a: Aprender a Cocinar

Imagina que est√°s aprendiendo a hacer una receta perfecta:

### Estado Inicial (Valores Aleatorios)
```
Receta inicial (aleatoria):
- Sal: 2 cucharadas (demasiado)
- Az√∫car: 0.5 cucharadas (muy poco)
- Tiempo de cocci√≥n: 10 minutos (insuficiente)
```

### Proceso de Aprendizaje
1. **Cocinas** con estos valores ‚Üí El resultado no est√° bueno
2. **Pruebas** el resultado ‚Üí "Est√° muy salado y poco dulce"
3. **Ajustas** los valores:
   - Reduces la sal (porque estaba muy salado)
   - Aumentas el az√∫car (porque estaba poco dulce)
   - Aumentas el tiempo (porque estaba crudo)
4. **Repites** hasta que el resultado sea perfecto

### En Redes Neuronales
- **Pesos y sesgos** = Los ingredientes y tiempos de la receta
- **Predicci√≥n** = El plato que cocinas
- **Respuesta correcta** = El plato perfecto que quieres lograr
- **Error** = Qu√© tan diferente est√° tu plato del perfecto
- **Ajuste** = Cambiar los ingredientes/tiempos para mejorar

---

## üìä El Proceso de Entrenamiento (Paso a Paso)

### 1. Inicializaci√≥n (Valores Aleatorios)

```javascript
// Al inicio, los pesos y sesgos son aleatorios
W = [
    [0.1, 0.5, -0.2],   // Valores peque√±os aleatorios
    [0.3, -0.4, 0.6]
]

b = [0.5, -0.1]  // Valores peque√±os aleatorios
```

**Analog√≠a:** Como empezar a cocinar con una receta que inventaste al azar.

---

### 2. Forward Pass (Hacer una Predicci√≥n)

```javascript
// La red hace una predicci√≥n
z = Wx + b
prediccion = activation(z)
```

**Ejemplo:**
```
Entrada: x = [5, 3, 2]
Pesos actuales: W = [[0.1, 0.5, -0.2], [0.3, -0.4, 0.6]]
Sesgos actuales: b = [0.5, -0.1]

C√°lculo:
z‚ÇÅ = (0.1√ó5) + (0.5√ó3) + (-0.2√ó2) + 0.5 = 2.1
z‚ÇÇ = (0.3√ó5) + (-0.4√ó3) + (0.6√ó2) + (-0.1) = 1.4

Predicci√≥n: [2.1, 1.4]
```

**Analog√≠a:** Cocinas el plato con los ingredientes actuales.

---

### 3. Calcular el Error (Comparar con la Respuesta Correcta)

```javascript
// Respuesta correcta (lo que deber√≠a dar)
respuesta_correcta = [3.0, 2.0]

// Error = diferencia entre predicci√≥n y respuesta correcta
error = respuesta_correcta - prediccion
error = [3.0, 2.0] - [2.1, 1.4] = [0.9, 0.6]
```

**Analog√≠a:** Comparas tu plato con el plato perfecto. "Mi plato tiene 0.9 unidades menos de sabor en el primer componente y 0.6 unidades menos en el segundo."

---

### 4. Backpropagation (Propagar el Error Hacia Atr√°s)

El algoritmo calcula **cu√°nto contribuye cada peso y sesgo al error**. Usa **derivadas** (c√°lculo diferencial) para saber:

- "Si aumento este peso un poco, ¬øel error aumenta o disminuye?"
- "¬øEn qu√© direcci√≥n debo ajustar este sesgo?"

**F√≥rmula b√°sica (simplificada):**
```
gradiente_peso = error √ó entrada
gradiente_sesgo = error
```

**Ejemplo:**
```
Para el peso w‚ÇÅ‚ÇÅ (primera neurona, primera entrada):
gradiente = error‚ÇÅ √ó x‚ÇÅ = 0.9 √ó 5 = 4.5

Para el sesgo b‚ÇÅ:
gradiente = error‚ÇÅ = 0.9
```

**Analog√≠a:** Analizas qu√© ingrediente caus√≥ m√°s el problema. "El primer ingrediente contribuy√≥ 4.5 unidades al error."

---

### 5. Actualizar los Pesos y Sesgos

```javascript
// Tasa de aprendizaje (qu√© tan grandes son los ajustes)
learning_rate = 0.01  // Peque√±o para ajustes suaves

// Actualizar pesos
W_nuevo = W_anterior - learning_rate √ó gradiente_peso

// Actualizar sesgos
b_nuevo = b_anterior - learning_rate √ó gradiente_sesgo
```

**Ejemplo pr√°ctico:**
```
Peso anterior: w‚ÇÅ‚ÇÅ = 0.1
Gradiente: 4.5
Learning rate: 0.01

w‚ÇÅ‚ÇÅ_nuevo = 0.1 - 0.01 √ó 4.5 = 0.1 - 0.045 = 0.055

Sesgo anterior: b‚ÇÅ = 0.5
Gradiente: 0.9

b‚ÇÅ_nuevo = 0.5 - 0.01 √ó 0.9 = 0.5 - 0.009 = 0.491
```

**Analog√≠a:** Ajustas los ingredientes. "Reduzco la sal en 0.045 unidades porque estaba contribuyendo demasiado al error."

---

### 6. Repetir (Muchas Veces)

Este proceso se repite **miles o millones de veces** con diferentes ejemplos hasta que la red aprende.

```
√âpoca 1:   Error = 0.9
√âpoca 2:   Error = 0.7
√âpoca 3:   Error = 0.5
...
√âpoca 1000: Error = 0.001  ‚Üê ¬°Casi perfecto!
```

---

## üîç Ejemplo Completo: Una Iteraci√≥n

### Configuraci√≥n Inicial
```javascript
// Entrada
x = [5, 3]

// Pesos (aleatorios al inicio)
W = [
    [0.6, -0.4],  // Pesos para neurona de salida 1
]

// Sesgo (aleatorio al inicio)
b = [0.5]

// Respuesta correcta (lo que queremos lograr)
y_correcto = 1  // Queremos que la neurona se active
```

### Paso 1: Forward Pass
```javascript
z = (0.6 √ó 5) + (-0.4 √ó 3) + 0.5
z = 3.0 + (-1.2) + 0.5
z = 2.3

prediccion = sigmoid(2.3) = 0.91  // Casi 1, est√° bien
```

### Paso 2: Calcular Error
```javascript
error = y_correcto - prediccion
error = 1 - 0.91 = 0.09  // Queremos que sea m√°s cercano a 1
```

### Paso 3: Calcular Gradientes
```javascript
// Gradiente del peso w‚ÇÅ (simplificado)
gradiente_w1 = error √ó x‚ÇÅ √ó derivada_sigmoid(z)
gradiente_w1 = 0.09 √ó 5 √ó 0.21 ‚âà 0.0945

// Gradiente del peso w‚ÇÇ
gradiente_w2 = error √ó x‚ÇÇ √ó derivada_sigmoid(z)
gradiente_w2 = 0.09 √ó 3 √ó 0.21 ‚âà 0.0567

// Gradiente del sesgo
gradiente_b = error √ó derivada_sigmoid(z)
gradiente_b = 0.09 √ó 0.21 ‚âà 0.0189
```

### Paso 4: Actualizar
```javascript
learning_rate = 0.1

// Actualizar pesos
w1_nuevo = 0.6 - 0.1 √ó 0.0945 = 0.59055
w2_nuevo = -0.4 - 0.1 √ó 0.0567 = -0.40567

// Actualizar sesgo
b_nuevo = 0.5 - 0.1 √ó 0.0189 = 0.49811
```

### Paso 5: Verificar Mejora
```javascript
// Nueva predicci√≥n con valores actualizados
z_nuevo = (0.59055 √ó 5) + (-0.40567 √ó 3) + 0.49811
z_nuevo = 2.295 + 0.49811 = 2.79311

prediccion_nueva = sigmoid(2.79311) = 0.942  // ¬°Mejor! (antes era 0.91)
```

---

## üéì Conceptos Clave

### 1. Learning Rate (Tasa de Aprendizaje)

**¬øQu√© es?**
- Controla qu√© tan grandes son los ajustes en cada paso

**Analog√≠a:**
- **Learning rate alto (0.1)**: Ajustes grandes, como cambiar la sal de 2 a 1 cucharada de golpe
- **Learning rate bajo (0.001)**: Ajustes peque√±os, como cambiar la sal de 2 a 1.99 cucharadas

**Problemas:**
- **Muy alto**: La red "salta" demasiado y no converge (como ajustar demasiado la receta)
- **Muy bajo**: La red aprende muy lento (como ajustar la receta muy poco a poco)

### 2. Gradiente (Derivada)

**¬øQu√© es?**
- Indica la **direcci√≥n** y **magnitud** del cambio necesario
- Es como una "br√∫jula" que dice "ajusta este peso hacia arriba o hacia abajo"

**Analog√≠a:**
- Si el gradiente es **positivo**: El peso es demasiado alto, hay que reducirlo
- Si el gradiente es **negativo**: El peso es demasiado bajo, hay que aumentarlo

### 3. Backpropagation (Propagaci√≥n Hacia Atr√°s)

**¬øQu√© es?**
- Algoritmo que calcula los gradientes de todas las capas, empezando desde la salida hacia las entradas

**Analog√≠a:**
- Como rastrear un error en una cadena de producci√≥n:
  1. Detectas el error en el producto final
  2. Rastreas hacia atr√°s: "¬øQu√© m√°quina caus√≥ esto?"
  3. Ajustas esa m√°quina
  4. Repites para todas las m√°quinas anteriores

---

## üìà Visualizaci√≥n del Proceso

```
Iteraci√≥n 1:
W = [0.6, -0.4], b = 0.5
Error = 0.09
‚Üì (ajuste)
Iteraci√≥n 2:
W = [0.59, -0.41], b = 0.498
Error = 0.08
‚Üì (ajuste)
Iteraci√≥n 3:
W = [0.58, -0.42], b = 0.496
Error = 0.07
‚Üì (ajuste)
...
Iteraci√≥n 100:
W = [0.45, -0.35], b = 0.4
Error = 0.001  ‚Üê ¬°Casi perfecto!
```

---

## üîß F√≥rmulas Matem√°ticas (Simplificadas)

### Para una Neurona Simple

```
1. Forward:
   z = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + b
   a = activation(z)

2. Error:
   error = y_correcto - a

3. Gradientes:
   ‚àÇerror/‚àÇw‚ÇÅ = error √ó x‚ÇÅ √ó activation'(z)
   ‚àÇerror/‚àÇw‚ÇÇ = error √ó x‚ÇÇ √ó activation'(z)
   ‚àÇerror/‚àÇb = error √ó activation'(z)

4. Actualizaci√≥n:
   w‚ÇÅ = w‚ÇÅ - learning_rate √ó ‚àÇerror/‚àÇw‚ÇÅ
   w‚ÇÇ = w‚ÇÇ - learning_rate √ó ‚àÇerror/‚àÇw‚ÇÇ
   b = b - learning_rate √ó ‚àÇerror/‚àÇb
```

Donde `activation'(z)` es la derivada de la funci√≥n de activaci√≥n.

---

## üéØ Resumen con Analog√≠a Final

**Aprender a cocinar:**
1. Empiezas con una receta aleatoria
2. Cocinas el plato
3. Lo pruebas y comparas con el plato perfecto
4. Identificas qu√© ingredientes est√°n mal (gradientes)
5. Ajustas los ingredientes un poco (learning rate)
6. Repites hasta que el plato sea perfecto

**Red neuronal:**
1. Empieza con pesos y sesgos aleatorios
2. Hace una predicci√≥n (forward pass)
3. Calcula el error comparando con la respuesta correcta
4. Calcula gradientes (backpropagation)
5. Actualiza pesos y sesgos (gradient descent)
6. Repite hasta que el error sea m√≠nimo

---

## üí° Puntos Clave

1. **Los pesos y sesgos NO se eligen manualmente** - Se aprenden autom√°ticamente
2. **El proceso es iterativo** - Se repite miles de veces
3. **Se usa c√°lculo diferencial** - Para saber en qu√© direcci√≥n ajustar
4. **El learning rate es crucial** - Controla la velocidad y estabilidad del aprendizaje
5. **Backpropagation es eficiente** - Calcula todos los gradientes de una vez

---

## üîó Relaci√≥n con tu Visualizaci√≥n

En tu visualizaci√≥n actual (`main.js`), los pesos y sesgos son **est√°ticos** (los defines manualmente). En una red neuronal real:

- Los valores iniciales ser√≠an **aleatorios**
- Despu√©s de cada predicci√≥n, se **actualizar√≠an autom√°ticamente**
- El proceso se repetir√≠a hasta que la red "aprenda" a hacer buenas predicciones

¬øTe gustar√≠a que agregue una simulaci√≥n de entrenamiento a tu visualizaci√≥n para ver c√≥mo se actualizan los pesos y sesgos en tiempo real?

